(4.1) What do you observe when the block size is increased from 8 to 64 for an 8K direct-mapped cache? What principle of cache operation is responsible for this effect?

As the block size increases, the number of misses and the overall missrate decreases. This is because when the block size increases, the cache explots spatial locality to accompluish the task of checking 
misses and hits. 

(4.2) What do you observe when you double the size of the direct-mapped cache (from 8K to 16K) while keeping the block size at 8? Discuss these results relative to your results from question 1. Is a bigger
cache necessarily better?

As the Cache size doubled, the miss rate decreased, but not significantly so. Generally, increasing the block size had a larger effect on the reduction of misses than the increasing of the cache size. While
a larger cache can help reduce misses, it is not perfect, and is not entirely computationally efficient. 

(4.3) What is the performance of a direct-mapped cache with sizes 32K, 64K, 128K, 256K, and 512K using a block size of 32? Is there a significant impact on the miss rate?

There really is not a significant influence on the miss rate, because from 16 -> 32k the change is less than .0003, from 32 -> 64k the change is less than .00004, from 64 -> 128k the change is less than 
.00002, and after this point the change is almost linear. 

(4.4) What is the effect of setting 2-way and 4-way set associativity for an 8K cache with a block size of 8? Is this what you expected? Explain your findings.

As the associativity increases, the relative number of hits stays the same, but the number of misses increases by just under a factor of 2. This is what you would expect, since the method of iterating 
through an associative cache results in a large amount of incorrect misses as it iterates through a larger number of values in order to search for cache hits. 

(4.5) What is the effect of setting 2-way and 4-way set associativity for a 128K cache with a block size of 8? Compare them to previous results and explain your findings.

These two caches had almost the same amount of hits and misses. Because the cache is so large, the cache does not fill up entirely over the majority of the indices which gives you the same results regardless
of the associativity. 


(6)
./cache_sim <cache_size> <block_size> <associativity> *FILE -> /tmp/$USER-blocked-8.log
The initial idea was to examine a subset of smaller caches and interate through different block sizes and associativites and see if it was possible to draw conclusions on the best performance. We examined 
cache sizes through 1k to 8k with between 8 and 32 block sizes, and different associativities between 1 and 4. Through this examination, we found that a larger block size was the most influential on the miss 
rate, and decided to focus on the block size as a parameter. We then started to examine the relative efficiency of larger caches on the miss rate, with an emphasis on larger block sizes. By doing this, we 
found that there was little influence on the relative efficiency. Given the goal, we decided that in order to maximize the efficiency of the cache, while keeping the cache small, we settled on a cache size of
 4k, a block size of 256, and an associativity of 4 which ultimately had a miss rate of about 0.01%. This was among the most efficient of the cache tests we ran as well as being one of the smallest caches we 
tested. When compared to the naive, we found that this level of efficiency can only be found in an idealized, perfect system, representing the fact that utilizing a blocking system that is efficent greatly 
influences the effective value of the cache. 
